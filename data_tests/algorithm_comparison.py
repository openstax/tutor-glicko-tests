# Load up real student data and do a 5-fold cross validation test using different methods

import pandas as pd
import numpy as np
from glicko.glicko import Glicko2
from irt.irt_3pl import IRT3PL
from sklearn.model_selection import KFold
from plotnine import *

# Data is not in the repo so have to set this to wherever we put it
# This file is generated by Ross's scripts
data_file = '~/Desktop/student_response_data.csv'
data = pd.read_csv(data_file)
data['response_correct'] = 1.0 * (data['response_correct']=='t')
data = data.rename(columns={'research_identifier': 'student', 'question_id': 'question', 'response_correct': 'score'})


# Grab the five courses with most students
courses = data.groupby('course_id')['student'].nunique().sort_values().iloc[-5:-2].index.values
data = data[data['course_id'].isin(courses)]

# Now let's do a cross validation experiment
# For each course, do a 5-fold with all the algorithms
df_output = pd.DataFrame(columns=['course', 'test_idx', 'algorithm', 'accuracy'])
for course in courses:
    data_temp = data[data['course_id']==course]
    data_temp = data_temp.drop_duplicates(['student', 'question'])[['student', 'question', 'score']].reset_index()

    # Filter down to most common 100 questions
    questions = data_temp.groupby('question')['student'].nunique().sort_values().iloc[-100:].index.values
    data_temp = data_temp[data_temp['question'].isin(questions)].drop(columns='index')

    # Set up the algorithms
    glicko = Glicko2()
    irt_1pl = IRT3PL(**{'model_name': '1pl'})
    algorithms = [glicko, irt_1pl]

    # Now do a five fold cross validation on the data
    kf = KFold(n_splits=5, random_state=42, shuffle=True)
    fold = 0
    for train_idx, test_idx in kf.split(data_temp):
        df_train = data_temp.iloc[train_idx]
        df_test = data_temp.iloc[test_idx]

        for alg in algorithms:
            alg.fit(df_train)
            df_out = alg.predict(df_test)
            df_out = df_out.merge(df_test)
            accuracy = 1 - np.mean(np.abs(np.round(df_out['p']) - df_out['score']))
            dft = pd.DataFrame({'course': [course],
                                'test_idx': [fold],
                                'algorithm': [alg.model_name],
                                'accuracy': [accuracy]
                                }
                               )
            df_output = df_output.append(dft)
        fold += 1

# Plot results and stuff
df_results = df_output.groupby(['algorithm'])['accuracy'].mean().reset_index()
fig_accuracy_comparison = ggplot(df_results, aes('algorithm', 'accuracy')) + geom_bar(stat='identity')




